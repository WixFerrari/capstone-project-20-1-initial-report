{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sktime.classification.interval_based import TimeSeriesForestClassifier\n",
    "from pyts.classification import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "test_df = pd.read_csv('CMAPSSData/test_FD001.txt', sep='\\s+', header=None)\n",
    "train_df = pd.read_csv('CMAPSSData/train_FD001.txt', sep='\\s+', header=None)\n",
    "\n",
    "# Preview first few rows\n",
    "print(test_df.head())\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column names based on the provided structure from pdf\n",
    "column_names = [\n",
    "    \"Unit\", \"ctime\", \"Setting1\", \"Setting2\", \"Setting3\",\n",
    "    \"inlet_temp\", \"LPC_Temp_Out\", \"HPC_Temp_Out\", \"LPT_Temp_Out\",\n",
    "    \"Fan_Pressure_In\", \"Total_Pressure_Bypass\", \"HPC_Pressure_Out\",\n",
    "    \"Fan_Speed\", \"Core_Speed\", \"Engine_Pressure_Ratio\", \"HPC_Static_Pressure\",\n",
    "    \"Fuel/Pressure_Ratio\", \"Fan_Speed_Correct\", \"Core_Speed_Correct\",\n",
    "    \"ByPass_Ratio\", \"Fuel/Air_Ratio\", \"Bleed_Enthalpy\", \"Demanded_Fan_Speed\",\n",
    "    \"Demand_Fan_Speed_Correct\", \"HPT_Coolant_Bleed\", \"LPT_Coolant_Bleed\",\n",
    "    \"Null\", \"Null2\"\n",
    "]\n",
    "\n",
    "# Load train and test data\n",
    "train_df = pd.read_csv('CMAPSSData/train_FD001.txt', sep=\"\\s+\", header=None, names=column_names)\n",
    "test_df = pd.read_csv('CMAPSSData/test_FD001.txt', sep=\"\\s+\", header=None, names=column_names)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "train_df.drop(columns=[\"Null\", \"Null2\"], inplace=True)\n",
    "test_df.drop(columns=[\"Null\", \"Null2\"], inplace=True)\n",
    "\n",
    "# Display first few rows for both train and test dataset\n",
    "print(train_df.head())\n",
    "print(test_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the failure time as the maximum ctime for each unit in training data\n",
    "train_df['failure_time'] = train_df.groupby('Unit')['ctime'].transform('max')\n",
    "\n",
    "# Display the first few rows of new training data\n",
    "print(train_df[['Unit', 'ctime', 'failure_time']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define colors using colormap\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(train_df['Unit'].unique())))\n",
    "\n",
    "# Plot failure times for each unit\n",
    "plt.figure(figsize=(20, 8))\n",
    "for i, unit in enumerate(sorted(train_df['Unit'].unique())):\n",
    "    unit_data = train_df[train_df['Unit'] == unit]\n",
    "    plt.bar(unit, unit_data['failure_time'].max(), color=colors[i], width=1.0)\n",
    "\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.ylabel('Failure Time (max ctime)', fontsize=14)\n",
    "plt.xlabel('Unit', fontsize=14)\n",
    "plt.title('Failure Time for Each Unit', fontsize=16)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns\n",
    "feature_columns = [\n",
    "    \"Setting1\", \"Setting2\", \"Setting3\",\n",
    "    \"inlet_temp\", \"LPC_Temp_Out\", \"HPC_Temp_Out\", \"LPT_Temp_Out\",\n",
    "    \"Fan_Pressure_In\", \"Total_Pressure_Bypass\", \"HPC_Pressure_Out\",\n",
    "    \"Fan_Speed\", \"Core_Speed\", \"Engine_Pressure_Ratio\", \"HPC_Static_Pressure\",\n",
    "    \"Fuel/Pressure_Ratio\", \"Fan_Speed_Correct\", \"Core_Speed_Correct\",\n",
    "    \"ByPass_Ratio\", \"Fuel/Air_Ratio\", \"Bleed_Enthalpy\", \"Demanded_Fan_Speed\",\n",
    "    \"Demand_Fan_Speed_Correct\", \"HPT_Coolant_Bleed\", \"LPT_Coolant_Bleed\"\n",
    "]\n",
    "\n",
    "X_train = train_df[feature_columns]\n",
    "y_train = train_df['failure_time']\n",
    "\n",
    "# Split data to training and validation sets\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Training Random Forest Regressor\n",
    "regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "regressor.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = regressor.predict(X_val)\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "print(f\"Validation MSE: {mse}, R2: {r2}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict failure time for test data\n",
    "X_test = train_df[feature_columns]\n",
    "train_df['predicted_failure_time'] = regressor.predict(X_test)\n",
    "\n",
    "# Display test data with predictions\n",
    "print(train_df[['Unit', 'ctime', 'predicted_failure_time']].head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Calculate the mean predicted failure time for each Unit\n",
    "unit_summary = train_df.groupby('Unit')['predicted_failure_time'].mean().reset_index()\n",
    "plt.figure(figsize=(18, 10))\n",
    "\n",
    "# Create bar plot with thicker bars\n",
    "barplot = sns.barplot(\n",
    "    x='Unit', \n",
    "    y='predicted_failure_time', \n",
    "    data=unit_summary, \n",
    "    palette='viridis'\n",
    ")\n",
    "\n",
    "# Adjust bar width by setting edge width and spacing\n",
    "for bar in barplot.patches:\n",
    "    bar.set_width(1.5)  # Increase bar thickness\n",
    "\n",
    "# Plot labeling\n",
    "plt.xticks(rotation=90, fontsize=12)\n",
    "plt.title('Average Predicted Failure Time per Unit', fontsize=20)\n",
    "plt.xlabel('Unit', fontsize=16)\n",
    "plt.ylabel('Average Predicted Failure Time', fontsize=16)\n",
    "plt.grid(axis='y', alpha=0.5)\n",
    "plt.tight_layout() \n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature importance from training model\n",
    "# Get feature importances from Random Forest model\n",
    "feature_importances = regressor.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_columns,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display feature importance\n",
    "print(feature_importance_df)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'], color='teal')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importance')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search for Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"max_depth\": [10, 20],\n",
    "    \"max_samples\": [0.8, 1.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=RandomForestRegressor(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    cv=3, verbose=2\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Evaluate the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_tuned = best_model.predict(X_val)\n",
    "mse_tuned = mean_squared_error(y_val, y_pred_tuned)\n",
    "r2_tuned = r2_score(y_val, y_pred_tuned)\n",
    "\n",
    "print(f\"Tuned Validation MSE: {mse_tuned}, R2: {r2_tuned}\")\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using the best model on the validation set\n",
    "y_pred_tuned = best_model.predict(X_val)\n",
    "\n",
    "# Calculate MSE and R2 for validation set\n",
    "mse_tuned = mean_squared_error(y_val, y_pred_tuned)\n",
    "r2_tuned = r2_score(y_val, y_pred_tuned)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Tuned Validation MSE: {mse_tuned}, R2: {r2_tuned}\")\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "# Plot the predictions vs true values\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# Plot the true vs predicted values\n",
    "plt.scatter(y_val, y_pred_tuned, color='blue', label='Predictions')\n",
    "plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], color='red', linewidth=2, label=\"Perfect Prediction\")\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('True Failure Rate')\n",
    "plt.ylabel('Predicted Failure Rate')\n",
    "plt.title('True vs Predicted Failure Rates (Random Forest)')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Optional: Plot the residuals\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(y_pred_tuned, y_pred_tuned - y_val, color='green', label='Residuals')\n",
    "plt.hlines(y=0, xmin=y_pred_tuned.min(), xmax=y_pred_tuned.max(), color='red', linewidth=2)\n",
    "plt.xlabel('Predicted Failure Rate')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals Plot (Random Forest)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define threshold value\n",
    "threshold = 300  \n",
    "\n",
    "# Filter data based on threshold \n",
    "train_df_filtered = train_df[train_df['failure_time'] <= threshold]\n",
    "\n",
    "# Define features and target after filtering\n",
    "X_failure = train_df_filtered[feature_columns]  # Select only the feature columns\n",
    "y_failure_time = train_df_filtered['failure_time']  # Use failure time for regression\n",
    "\n",
    "# Split data into train and test set\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_failure, y_failure_time, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_reg_scaled = scaler.fit_transform(X_train_reg)\n",
    "X_test_reg_scaled = scaler.transform(X_test_reg)\n",
    "\n",
    "# Train KNN regressor\n",
    "knn_reg = KNeighborsRegressor(n_neighbors=10)  # Default to 10 neighbors\n",
    "knn_reg.fit(X_train_reg_scaled, y_train_reg)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and find MSE\n",
    "y_pred = knn_reg.predict(X_test_reg_scaled)\n",
    "mse = mean_squared_error(y_test_reg, y_pred)\n",
    "r2 = r2_score(y_test_reg, y_pred)\n",
    "\n",
    "print(f\"Validation MSE: {mse}, R2: {r2}\")\n",
    "\n",
    "\n",
    "# Plot True vs Predicted values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(y_test_reg, y_pred, color='blue', label='Predictions')\n",
    "plt.plot([y_test_reg.min(), y_test_reg.max()], [y_test_reg.min(), y_test_reg.max()], 'r-', label='Perfect Prediction')\n",
    "plt.xlabel(\"True Failure Time\")\n",
    "plt.ylabel(\"Predicted Failure Time\")\n",
    "plt.title(\"True vs Predicted Failure Times (KNN)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot Residuals\n",
    "residuals = y_test_reg - y_pred\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(y_pred, residuals, color='green', label='Residuals')\n",
    "plt.axhline(y=0, color='red', linestyle='--')\n",
    "plt.xlabel(\"Predicted Failure Time\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residuals Plot (KNN)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting with Lag Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to redo this code for some reason or it will fail\n",
    "# Define column names for dataset\n",
    "column_names = [\n",
    "    \"Unit\", \"ctime\", \"Setting1\", \"Setting2\", \"Setting3\",\n",
    "    \"inlet_temp\", \"LPC_Temp_Out\", \"HPC_Temp_Out\", \"LPT_Temp_Out\",\n",
    "    \"Fan_Pressure_In\", \"Total_Pressure_Bypass\", \"HPC_Pressure_Out\",\n",
    "    \"Fan_Speed\", \"Core_Speed\", \"Engine_Pressure_Ratio\", \"HPC_Static_Pressure\",\n",
    "    \"Fuel/Pressure_Ratio\", \"Fan_Speed_Correct\", \"Core_Speed_Correct\",\n",
    "    \"ByPass_Ratio\", \"Fuel/Air_Ratio\", \"Bleed_Enthalpy\", \"Demanded_Fan_Speed\",\n",
    "    \"Demand_Fan_Speed_Correct\", \"HPT_Coolant_Bleed\", \"LPT_Coolant_Bleed\",\n",
    "    \"Null\", \"Null2\"\n",
    "]\n",
    "\n",
    "# Load train and test data\n",
    "train_df = pd.read_csv('CMAPSSData/train_FD001.txt', sep=\"\\s+\", header=None, names=column_names)\n",
    "test_df = pd.read_csv('CMAPSSData/test_FD001.txt', sep=\"\\s+\", header=None, names=column_names)\n",
    "\n",
    "# Drop unnecessary columns again\n",
    "train_df.drop(columns=[\"Null\", \"Null2\"], inplace=True)\n",
    "test_df.drop(columns=[\"Null\", \"Null2\"], inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create lag-based features\n",
    "def create_lagged_features(data, target_col, lag=3):\n",
    "    df = data[[target_col]].copy()\n",
    "    for i in range(1, lag + 1):\n",
    "        df[f\"lag_{i}\"] = df[target_col].shift(i)\n",
    "    return df.dropna()\n",
    "\n",
    "# Store predictions temporarily\n",
    "unit_predictions = []\n",
    "\n",
    "# Process each unit\n",
    "for unit in train_df[\"Unit\"].unique():\n",
    "    print(f\"Processing Unit {unit}...\")\n",
    "    unit_data = train_df[train_df[\"Unit\"] == unit]\n",
    "\n",
    "    # Create lagged features\n",
    "    lagged_data = create_lagged_features(unit_data, target_col=\"ctime\", lag=3)\n",
    "\n",
    "    # Prepare features and target\n",
    "    X = lagged_data.drop(columns=[\"ctime\"])\n",
    "    y = lagged_data[\"ctime\"]\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize/train the model\n",
    "    gbr = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "    gbr.fit(X_train, y_train)\n",
    "\n",
    "    # Predict failure times\n",
    "    y_pred = gbr.predict(X_test)\n",
    "\n",
    "    # Store mean prediction\n",
    "    mean_pred = y_pred.mean()\n",
    "    unit_predictions.append((unit, mean_pred))\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f\"Unit {unit} - Mean Squared Error: {mse:.2f}\")\n",
    "    \n",
    "    # Plot feature importance for each unit, might keep might get rid of later in the final version\n",
    "    #feature_importance = gbr.feature_importances_\n",
    "    #plt.barh(X_train.columns, feature_importance)\n",
    "    #plt.title(f\"Feature Importance - Unit {unit}\")\n",
    "    #plt.show()\n",
    "\n",
    "# Convert predictions to a DataFrame\n",
    "predictions_df = pd.DataFrame(unit_predictions, columns=[\"Unit\", \"Predicted_Failure_Time\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to clean up the plot x axis\n",
    "plt.figure(figsize=(14, 8))  \n",
    "plt.bar(predictions_df[\"Unit\"], predictions_df[\"Predicted_Failure_Time\"], color=\"skyblue\", edgecolor=\"black\")\n",
    "plt.xlabel(\"Unit\", fontsize=14)\n",
    "plt.ylabel(\"Predicted Failure Time\", fontsize=14)\n",
    "plt.title(\"Predicted Failure Time for Each Unit\", fontsize=16)\n",
    "plt.xticks(predictions_df[\"Unit\"], rotation=45, ha=\"right\", fontsize=10)  \n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)  \n",
    "plt.tight_layout()  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display table of units and their predicted failure times\n",
    "print(\"Predicted Failure Times for Each Unit:\")\n",
    "print(predictions_df[[\"Unit\", \"Predicted_Failure_Time\"]].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
